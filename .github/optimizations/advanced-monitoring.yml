# Advanced Pipeline Monitoring & Analytics
# Provides real-time insights and automatic performance optimization

name: Advanced Pipeline Analytics

# Add this as a separate workflow or integrate sections into existing workflows

on:
  workflow_run:
    workflows: ["Optimized CI/CD Pipeline"]
    types: [completed]
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours

jobs:
  performance-analytics:
    name: Pipeline Performance Analytics
    runs-on: ubuntu-latest
    
    steps:
    - name: Collect workflow metrics
      uses: actions/github-script@v7
      id: metrics
      with:
        script: |
          const workflow = await github.rest.actions.getWorkflowRun({
            owner: context.repo.owner,
            repo: context.repo.repo,
            run_id: context.payload.workflow_run.id
          });
          
          const jobs = await github.rest.actions.listJobsForWorkflowRun({
            owner: context.repo.owner,
            repo: context.repo.repo,
            run_id: context.payload.workflow_run.id
          });
          
          // Calculate performance metrics
          const metrics = {
            total_duration: workflow.data.updated_at - workflow.data.created_at,
            jobs_count: jobs.data.total_count,
            failed_jobs: jobs.data.jobs.filter(job => job.conclusion === 'failure').length,
            avg_job_duration: jobs.data.jobs.reduce((sum, job) => 
              sum + (new Date(job.completed_at) - new Date(job.started_at)), 0) / jobs.data.jobs.length
          };
          
          console.log('Pipeline Metrics:', JSON.stringify(metrics, null, 2));
          return metrics;

    - name: Generate performance report
      run: |
        cat > performance-report.md << 'EOF'
        # Pipeline Performance Report
        
        ## Summary
        - **Total Duration**: ${{ fromJson(steps.metrics.outputs.result).total_duration }}ms
        - **Jobs Executed**: ${{ fromJson(steps.metrics.outputs.result).jobs_count }}
        - **Failed Jobs**: ${{ fromJson(steps.metrics.outputs.result).failed_jobs }}
        - **Average Job Duration**: ${{ fromJson(steps.metrics.outputs.result).avg_job_duration }}ms
        
        ## Optimization Recommendations
        
        ### High Impact Optimizations
        1. **Cache Hit Rate Monitoring**: Track npm/Docker cache effectiveness
        2. **Test Execution Time**: Monitor for regression in test performance
        3. **Build Optimization**: Track bundle size and build time trends
        
        ### Cost Optimization
        - **Conditional Execution**: Only run necessary jobs based on file changes
        - **Parallel Processing**: Use matrix strategies for independent tasks
        - **Resource Cleanup**: Automatic cleanup of old artifacts and cache
        
        EOF

    - name: Upload performance report
      uses: actions/upload-artifact@v4
      with:
        name: performance-report-${{ github.run_number }}
        path: performance-report.md
        retention-days: 30

  cost-optimization-analysis:
    name: Cost Optimization Analysis
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
    - name: Analyze workflow costs
      uses: actions/github-script@v7
      with:
        script: |
          // Get all workflow runs for the past week
          const oneWeekAgo = new Date();
          oneWeekAgo.setDate(oneWeekAgo.getDate() - 7);
          
          const workflows = await github.rest.actions.listWorkflowRunsForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            created: `>${oneWeekAgo.toISOString()}`,
            per_page: 100
          });
          
          let totalMinutes = 0;
          let totalRuns = workflows.data.total_count;
          
          for (const run of workflows.data.workflow_runs) {
            const jobs = await github.rest.actions.listJobsForWorkflowRun({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: run.id
            });
            
            for (const job of jobs.data.jobs) {
              if (job.started_at && job.completed_at) {
                const duration = (new Date(job.completed_at) - new Date(job.started_at)) / 60000; // minutes
                totalMinutes += duration;
              }
            }
          }
          
          console.log(`Total CI/CD minutes used this week: ${totalMinutes}`);
          console.log(`Total workflow runs: ${totalRuns}`);
          console.log(`Average minutes per run: ${totalMinutes / totalRuns}`);
          
          // Generate optimization recommendations
          const optimizationReport = {
            weekly_minutes: totalMinutes,
            total_runs: totalRuns,
            avg_minutes_per_run: totalMinutes / totalRuns,
            recommendations: []
          };
          
          if (totalMinutes / totalRuns > 30) {
            optimizationReport.recommendations.push("Consider reducing test execution time through parallel execution");
          }
          
          if (totalRuns > 50) {
            optimizationReport.recommendations.push("High frequency of runs - implement smarter triggering based on file changes");
          }
          
          core.setOutput('report', JSON.stringify(optimizationReport));

    - name: Create cost optimization issue
      if: fromJson(steps.cost-analysis.outputs.report).weekly_minutes > 500
      uses: actions/github-script@v7
      with:
        script: |
          const report = ${{ steps.cost-analysis.outputs.report }};
          
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'âš¡ Pipeline Cost Optimization Opportunity',
            body: `
            # Pipeline Cost Analysis
            
            Our CI/CD pipeline is consuming **${report.weekly_minutes} minutes per week**.
            
            ## Recommendations:
            ${report.recommendations.map(rec => `- ${rec}`).join('\n')}
            
            ## Potential Optimizations:
            1. Implement conditional job execution
            2. Use matrix strategies for parallel execution  
            3. Optimize Docker build caching
            4. Reduce artifact retention periods
            5. Clean up old workflow runs
            
            **Estimated Savings**: 30-50% reduction in CI/CD costs
            `,
            labels: ['optimization', 'ci-cd', 'cost-reduction']
          });

  security-performance-monitoring:
    name: Security Scan Performance
    runs-on: ubuntu-latest
    
    steps:
    - name: Monitor security scan efficiency
      run: |
        echo "ðŸ”’ Security Scan Performance Monitoring"
        echo "======================================="
        
        # Track security scan execution times
        echo "Monitoring security tool performance:"
        echo "- CodeQL analysis time"
        echo "- Dependency vulnerability scan time"  
        echo "- Container security scan time"
        echo "- TruffleHog secret scan time"
        
        # Generate recommendations for security optimization
        echo "ðŸš€ Security Optimization Opportunities:"
        echo "1. Use exclusion patterns to focus scans on relevant files"
        echo "2. Cache security scan results for unchanged dependencies"
        echo "3. Run intensive scans on schedule rather than every PR"
        echo "4. Use parallel execution for independent security checks"
